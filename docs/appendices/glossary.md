---
sidebar_position: 1
title: "Glossary"
description: "Key terms and definitions for Physical AI and Humanoid Robotics."
---

# Glossary

## A

- **Action Space** — The set of all possible actions a robot can take (e.g., joint torques, velocities)
- **Affordance** — What an object offers for interaction (e.g., a handle affords grasping)
- **Ament** — ROS 2 build system for Python and C++ packages

## B

- **Behavior Tree (BT)** — A hierarchical model for task execution with fallbacks and sequences

## C

- **Colcon** — The build tool for ROS 2 workspaces
- **COM (Center of Mass)** — The average position of mass in a body; critical for balance
- **Costmap** — A 2D grid representing traversability costs for navigation

## D

- **DDS (Data Distribution Service)** — The communication middleware underlying ROS 2
- **Degree of Freedom (DOF)** — An independent axis of motion (a humanoid has ~30 DOF)
- **Digital Twin** — A virtual replica of a physical system synchronized in real-time
- **Domain Randomization** — Varying simulation parameters to improve sim-to-real transfer

## E

- **Embodied Intelligence** — Intelligence that arises from physical interaction with the world
- **End-Effector** — The device at the end of a robotic arm (gripper, hand, tool)

## F

- **Forward Kinematics** — Computing end-effector position from joint angles
- **Foundation Model** — A large AI model trained on broad data, adaptable to many tasks

## G

- **Gazebo** — Open-source robotics simulator with physics and sensor simulation
- **GR00T** — NVIDIA's foundation model for humanoid robots
- **Gripper** — A device for grasping objects

## I

- **IMU (Inertial Measurement Unit)** — Sensor measuring acceleration and angular velocity
- **Inverse Kinematics (IK)** — Computing joint angles to achieve a desired end-effector position
- **Isaac Sim** — NVIDIA's GPU-accelerated robotics simulator built on Omniverse

## L

- **LiDAR** — Light Detection and Ranging sensor for 3D distance measurement
- **Locomotion** — The ability to move through the environment (walking, running)

## M

- **MoveIt2** — ROS 2 package for motion planning and manipulation

## N

- **Nav2** — ROS 2 Navigation Stack for autonomous navigation
- **Node** — A single, modular process in ROS 2

## O

- **Occupancy Grid** — A 2D map where each cell indicates free, occupied, or unknown
- **Odometry** — Estimating position changes from sensor data (wheel encoders, IMU)
- **Omniverse** — NVIDIA's platform for building and simulating 3D worlds

## P

- **PhysX** — NVIDIA's GPU-accelerated physics engine
- **Physical AI** — AI systems that perceive, reason about, and act in the physical world
- **Proprioception** — A robot's sense of its own joint positions and velocities
- **PPO** — Proximal Policy Optimization, a common RL algorithm

## Q

- **QoS (Quality of Service)** — DDS policies controlling message delivery reliability
- **Quaternion** — A 4-component representation of 3D rotation (w, x, y, z)

## R

- **RLDS** — Reinforcement Learning Datasets format for storing robot demonstrations
- **ROS 2** — Robot Operating System 2, the standard middleware for robotics
- **RL (Reinforcement Learning)** — Learning through trial and error with rewards

## S

- **SDF (Simulation Description Format)** — XML format for describing simulation worlds
- **SLAM** — Simultaneous Localization and Mapping
- **Sim-to-Real** — Transferring behaviors from simulation to real hardware

## T

- **TensorRT** — NVIDIA's inference optimizer for deploying neural networks
- **tf2** — ROS 2 transform library for coordinate frame management
- **Topic** — A named communication channel in ROS 2

## U

- **URDF** — Unified Robot Description Format (XML-based robot model)
- **USD** — Universal Scene Description (3D scene format by Pixar)

## V

- **VLA (Vision-Language-Action)** — Models combining vision, language, and robot action
- **VSLAM** — Visual SLAM using camera images

## Z

- **ZMP (Zero Moment Point)** — The point where ground reaction forces produce zero torque; critical for bipedal balance
